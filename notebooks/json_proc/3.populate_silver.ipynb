{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a70c861-f334-4434-b5b3-806a0f8f265e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"DROP DATABASE IF EXISTS silver CASCADE\")\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS silver\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f041375-1d3a-4b7a-aa1b-cd10224124d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_audit_table(\"EV_Data\", progress=\"Ingest_Silver\", status=\"In_Progress\", start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb867e4-542d-48bc-8543-8e3ddd1f47ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, regexp_replace, trim\n",
    "\n",
    "# Step 1: Define your database and table names\n",
    "bronze_database_name = \"bronze\"\n",
    "columns_metadata_table = \"columns_metadata\"\n",
    "silver_database_name = \"silver\"\n",
    "new_table_name = \"ev_std\"\n",
    "\n",
    "# Step 2: Fetch the schema of your original table (columns metadata)\n",
    "df = spark.sql(f\"SELECT name, dataTypeName FROM {bronze_database_name}.{columns_metadata_table}\")\n",
    "df.limit(10).show()\n",
    "\n",
    "# Step 3: Apply the mapping to convert your custom dataTypeName to actual SQL data types\n",
    "df_with_sql_types = df.withColumn(\n",
    "    \"SQL_DataType\",\n",
    "    when(df.dataTypeName == \"number\", \"DOUBLE\")\n",
    "    .when(df.dataTypeName == \"text\", \"STRING\")\n",
    "    .when(df.dataTypeName == \"point\", \"STRING\")\n",
    "    .when(df.dataTypeName == \"meta_data\", \"STRING\")\n",
    "    .otherwise(\"UNKNOWN\")\n",
    ")\n",
    "\n",
    "# Step 4: Correct only the 'name' column by replacing spaces and dashes with underscores using regexp_replace\n",
    "df_with_sql_types = df_with_sql_types.withColumn(\n",
    "    \"name\",\n",
    "    regexp_replace(col(\"name\"), \"[^a-zA-Z0-9]+\", \"_\")\n",
    ")\n",
    "df_with_sql_types = df_with_sql_types.withColumn(\n",
    "    \"name\",\n",
    "    trim(regexp_replace(col(\"name\"), \"^_+|_+$\", \"\"))\n",
    ")\n",
    "\n",
    "# Step 5: Display the corrected schema with column names and data types\n",
    "df_with_sql_types.limit(10).show()\n",
    "\n",
    "# Step 6: Generate the CREATE TABLE statement based on the corrected schema\n",
    "columns_with_types = [\n",
    "    f\"`{row['name']}` {row['SQL_DataType']}\" for row in df_with_sql_types.collect()\n",
    "]\n",
    "\n",
    "create_table_statement = f\"\"\"\n",
    "CREATE TABLE if not exists {silver_database_name}.{new_table_name} (\n",
    "    {', '.join(columns_with_types)}\n",
    ") USING DELTA \n",
    "\"\"\"\n",
    "\n",
    "# Step 7: Print the CREATE TABLE statement for verification\n",
    "print(create_table_statement)\n",
    "\n",
    "# Execute the SQL statement to create the new table\n",
    "spark.sql(create_table_statement)\n",
    "\n",
    "# Confirm the table has been created successfully\n",
    "print(f\"Table {silver_database_name}.{new_table_name} has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb2ffa-c7ba-4962-8983-92cbd837096a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_type_correction(bronze_df):\n",
    "    \n",
    "    bronze_df = bronze_df.withColumn(\"created_at\", bronze_df[\"created_at\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"updated_at\", bronze_df[\"updated_at\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Postal_Code\", bronze_df[\"Postal_code\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Model_year\", bronze_df[\"Model_year\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"2020_Census_Tract\", bronze_df[\"2020_Census_Tract\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Counties\", bronze_df[\"Counties\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Electric_Range\", bronze_df[\"Electric_Range\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Base_MSRP\", bronze_df[\"Base_MSRP\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Legislative_District\", bronze_df[\"Legislative_District\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"DOL_Vehicle_ID\", bronze_df[\"DOL_Vehicle_ID\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"Congressional_Districts\", bronze_df[\"Congressional_Districts\"].cast(DoubleType()))\\\n",
    "                        .withColumn(\"WAOFM_GIS_Legislative_District_Boundary\", bronze_df[\"WAOFM_GIS_Legislative_District_Boundary\"].cast(DoubleType()))\n",
    "    bronze_df = bronze_df.withColumn(\"created_at\",to_timestamp(from_unixtime(col(\"created_at\"))))\\\n",
    "                           .withColumn(\"updated_at\",to_timestamp(from_unixtime(col(\"updated_at\"))))\n",
    "\n",
    "    return bronze_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ed8ef-ca34-4228-8f9c-1fdc30820d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def us_state_validation(bronze_df):\n",
    "\n",
    "    valid_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', \n",
    "                'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', \n",
    "                'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', \n",
    "                'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "    bronze_df = bronze_df.withColumn(\"err_code\", when(~col(\"State\").isin(valid_states), concat(col(\"err_code\"), lit(\"DQ01\"))).otherwise(col(\"err_code\")))\\\n",
    "    .withColumn(\"err_message\", when(~col(\"State\").isin(valid_states), concat(col(\"err_message\"), lit(\"Invalid Sate\"))).otherwise(col(\"err_message\")))\n",
    "    bronze_df = bronze_df.withColumn(\"err_flg\", when(col(\"err_code\") != \"\", \"Y\").otherwise(\"N\"))\n",
    "    return bronze_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d90bb-d1af-4630-8f00-5b32798fbbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def null_check(bronze_df):\n",
    "    # List of columns to check for null values, excluding the specified ones\n",
    "    columns = [col_name for col_name in bronze_df.columns if col_name not in [\"err_code\", \"err_message\", \"updated_meta\", \"created_meta\"]]\n",
    "\n",
    "    # Initialize null check for all columns together, so we only add error once\n",
    "    null_condition = None\n",
    "\n",
    "    for column in columns:\n",
    "        # Create a condition to check if any of the columns has a null value\n",
    "        column_null_condition = col(column).isNull()\n",
    "        if null_condition is None:\n",
    "            null_condition = column_null_condition\n",
    "        else:\n",
    "            null_condition = null_condition | column_null_condition\n",
    "\n",
    "    # Apply the error code and message only once if any column has a null value\n",
    "    bronze_df = bronze_df.withColumn(\n",
    "        \"err_code\",\n",
    "        when((instr(col(\"err_code\"), \"DQ02\") == 0) & null_condition, \n",
    "             concat(col(\"err_code\"), lit(\"DQ02 \"))\n",
    "        ).otherwise(col(\"err_code\"))\n",
    "    ).withColumn(\n",
    "        \"err_message\",\n",
    "        when((instr(col(\"err_message\"), \"Null value\") == 0) & null_condition, \n",
    "             concat(col(\"err_message\"), lit(\"Null value \"))\n",
    "        ).otherwise(col(\"err_message\"))\n",
    "    )\n",
    "    \n",
    "    # Adding a final flag to indicate if there are any errors\n",
    "    bronze_df = bronze_df.withColumn(\"err_flg\", when(col(\"err_code\") != \"\", lit(\"Y\")).otherwise(lit(\"N\")))\n",
    "\n",
    "    return bronze_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e285e4c-950b-4b94-87dd-858e7060ca89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numeric_check(bronze_df):\n",
    "    # List of numeric columns only\n",
    "    numeric_columns = [field.name for field in bronze_df.schema.fields if field.dataType.simpleString() in ['int', 'double', 'float', 'long', 'decimal']]\n",
    "\n",
    "    # Initialize numeric check for all columns together, so we only add error once\n",
    "    invalid_numeric_condition = None\n",
    "\n",
    "    for column in numeric_columns:\n",
    "        # Create a condition to check if any of the columns has an invalid numeric value (NaN)\n",
    "        column_invalid_condition = isnan(col(column))  # Check only for NaN (exclude nulls)\n",
    "\n",
    "        # Combine conditions across all numeric columns\n",
    "        if invalid_numeric_condition is None:\n",
    "            invalid_numeric_condition = column_invalid_condition\n",
    "        else:\n",
    "            invalid_numeric_condition = invalid_numeric_condition | column_invalid_condition\n",
    "\n",
    "    # Apply the error code and message only once if any column has an invalid numeric value\n",
    "    bronze_df = bronze_df.withColumn(\n",
    "        \"err_code\",\n",
    "        when((instr(col(\"err_code\"), \"DQ04\") == 0) & invalid_numeric_condition, \n",
    "             concat(col(\"err_code\"), lit(\"DQ04 \"))\n",
    "        ).otherwise(col(\"err_code\"))\n",
    "    ).withColumn(\n",
    "        \"err_message\",\n",
    "        when((instr(col(\"err_message\"), \"Invalid Numeric Value\") == 0) & invalid_numeric_condition, \n",
    "             concat(col(\"err_message\"), lit(\"Invalid Numeric Value \"))\n",
    "        ).otherwise(col(\"err_message\"))\n",
    "    )\n",
    "\n",
    "    # Adding a final flag to indicate if there are any errors\n",
    "    bronze_df = bronze_df.withColumn(\"err_flg\", when(col(\"err_code\") != \"\", lit(\"Y\")).otherwise(lit(\"N\")))\n",
    "\n",
    "    return bronze_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d49cfa-e6bb-4277-8af9-ed30b24904e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def year_check(bronze_df):\n",
    "    current_year = datetime.now().year\n",
    "    \n",
    "    # Corrected the parentheses to ensure correct logical operation order\n",
    "    bronze_df = bronze_df.withColumn(\n",
    "        \"err_code\", \n",
    "        when((col(\"Model_year\") <= current_year) & (col(\"Model_year\") < 1900),\n",
    "             concat(col(\"err_code\"), lit(\"DQ03 \"))\n",
    "        ).otherwise(col(\"err_code\"))\n",
    "    )\n",
    "    \n",
    "    bronze_df = bronze_df.withColumn(\n",
    "        \"err_message\", \n",
    "        when((col(\"Model_year\") <= current_year) & (col(\"Model_year\") < 1900),\n",
    "             concat(col(\"err_message\"), lit(\"Invalid Model Year \"))\n",
    "        ).otherwise(col(\"err_message\"))\n",
    "    )\n",
    "\n",
    "    bronze_df = bronze_df.withColumn(\"err_flg\", when(col(\"err_code\") != \"\", lit(\"Y\")).otherwise(lit(\"N\")))\n",
    "    \n",
    "    return bronze_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0b8fe-c4ef-4019-861b-4cc4fbb540ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, concat, lit, instr, isnan, to_timestamp, from_unixtime\n",
    "from pyspark.sql.types import TimestampType, DoubleType\n",
    "from datetime import datetime\n",
    "\n",
    "source_database_name = \"bronze\"\n",
    "source_table_name = \"vehicle_data\" \n",
    "bronze_df = spark.sql(f\"SELECT * FROM {source_database_name}.{source_table_name}\")\n",
    "bronze_df = bronze_df.withColumn(\"err_code\", lit(\"\")).withColumn(\"err_message\", lit(\"\"))\n",
    "bronze_df = data_type_correction(bronze_df)\n",
    "bronze_df = null_check(bronze_df)\n",
    "bronze_df = year_check(bronze_df)\n",
    "bronze_df = numeric_check(bronze_df)\n",
    "# Create the table by writing data to it\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver.vehicle_data\")\n",
    "bronze_df.limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99d67f-bb23-40d8-8b70-8a4182512020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_audit_table(\"EV_Data\", progress=\"Ingest_Silver\", status=\"Completed\", end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47746f-6465-4a2f-adf0-600dc6ba8f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
