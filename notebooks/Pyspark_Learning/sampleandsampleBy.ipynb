{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a2d9e-cfc1-451c-b93e-9595c3061085",
   "metadata": {},
   "outputs": [],
   "source": [
    "PySpark provides a pyspark.sql.DataFrame.sample(), pyspark.sql.DataFrame.sampleBy(), RDD.sample(), and RDD.takeSample() methods\n",
    "to get the random sampling subset from the large dataset\n",
    "\n",
    "Syntax:\n",
    "    sample(withReplacement, fraction, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5ad205-4888-4161-a6db-a4a35aa4e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "PySpark sampling can be done on RDD and DataFrame. In order to do sampling, you need to know how much data you wanted to retrieve by specifying fractions.\n",
    "Use seed to regenerate the same sampling multiple times. and\n",
    "Use withReplacement if you are okay to repeat the random records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd4e2a9-fa7b-4243-b641-9a1dfe8033d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(id=49), Row(id=56), Row(id=57), Row(id=90)]\n",
      "[Row(id=36), Row(id=37), Row(id=41), Row(id=43), Row(id=56), Row(id=66), Row(id=69), Row(id=75), Row(id=83)]\n",
      "[Row(id=19), Row(id=21), Row(id=42), Row(id=48), Row(id=49), Row(id=50), Row(id=75), Row(id=80)]\n",
      "[Row(id=0), Row(id=5), Row(id=9), Row(id=11), Row(id=14), Row(id=14), Row(id=16), Row(id=17), Row(id=21), Row(id=29), Row(id=33), Row(id=41), Row(id=42), Row(id=52), Row(id=52), Row(id=54), Row(id=58), Row(id=65), Row(id=65), Row(id=71), Row(id=76), Row(id=79), Row(id=85), Row(id=96)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName(\"SparkByExamples.com\").getOrCreate()\n",
    "\n",
    "#Using fraction    \n",
    "df=spark.range(100)\n",
    "print(df.sample(0.06).collect())\n",
    "\n",
    "#Using seed\n",
    "print(df.sample(0.1,123).collect())\n",
    "\n",
    "print(df.sample(0.1,456).collect())\n",
    "\n",
    "#Using replacement-May contain duplicates\n",
    "print(df.sample(True,0.3,123).collect())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5c813-2517-43c4-9b37-7a0cecd63507",
   "metadata": {},
   "outputs": [],
   "source": [
    "You can get Stratified sampling in PySpark without replacement by using sampleBy() method. It returns a sampling fraction \n",
    "for each stratum. If a stratum is not specified, it takes zero as the default.\n",
    "Syntax :sampleBy(col, fractions, seed=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a3c6abf-5254-4343-8e99-32fbcb685a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(key=0), Row(key=1), Row(key=1), Row(key=1), Row(key=0), Row(key=1), Row(key=1), Row(key=0), Row(key=1), Row(key=1), Row(key=1)]\n"
     ]
    }
   ],
   "source": [
    "df2=df.select((df.id % 3).alias(\"key\"))\n",
    "print(df2.sampleBy(\"key\", {0: 0.1, 1: 0.2},0).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ca500-d5b7-471e-b171-77df6af865d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pyspark rdd sample\n",
    "syntax: sample(self, withReplacement, fraction, seed=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d976b4d2-b1f0-4ad5-a951-235ae0fb5410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 29, 41, 64, 86]\n",
      "[0, 11, 13, 14, 16, 18, 21, 23, 27, 31, 32, 32, 48, 49, 49, 53, 54, 72, 74, 77, 77, 83, 88, 91, 93, 98, 99]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.range(0,100)\n",
    "print(rdd.sample(False,0.1,0).collect())\n",
    "print(rdd.sample(True,0.3,123).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9678b-c07a-4727-97b0-14d1337d1bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD takeSample() is an action hence you need to careful when you use this function as it returns the selected sample records to driver memory. \n",
    "Returning too much data results in an out-of-memory error similar to collect().\n",
    "syntax:takeSample(self, withReplacement, num, seed=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a6de7ce-0677-437c-8cac-80413685f448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 1, 96, 74, 29, 24, 32, 37, 94, 91]\n",
      "[43, 65, 39, 18, 84, 86, 25, 13, 40, 21, 79, 63, 7, 32, 26, 71, 23, 61, 83, 60, 22, 35, 84, 22, 0, 88, 16, 40, 65, 84]\n"
     ]
    }
   ],
   "source": [
    "print(rdd.takeSample(False,10,0))\n",
    "print(rdd.takeSample(True,30,123))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e022dde-eb64-44f8-b573-976d275dc259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
