{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccd07c-d6d9-4fd3-8228-0455a351d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PySpark MapType (also called map type) is a data type to represent Python Dictionary (dict) to store key-value pair,\n",
    "a MapType object comprises three fields, keyType (a DataType), valueType (a DataType) and valueContainsNull (a BooleanType).\n",
    "\n",
    "PySpark MapType is used to represent map key-value pair similar to python Dictionary (Dict), it extends DataType class which \n",
    "is a superclass of all types in PySpark and takes two mandatory arguments keyType and valueType of type DataType and one \n",
    "optional boolean argument valueContainsNull. keyType and valueType can be any type that extends the DataType class. \n",
    "for e.g StringType, IntegerType, ArrayType, MapType, StructType (struct) e.t.c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0726fb73-994d-43fd-b488-f1dc2311667d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+----------+-----------------------------+\n",
      "|name      |properties                   |\n",
      "+----------+-----------------------------+\n",
      "|James     |{eye -> brown, hair -> black}|\n",
      "|Michael   |{eye -> null, hair -> brown} |\n",
      "|Robert    |{eye -> black, hair -> red}  |\n",
      "|Washington|{eye -> grey, hair -> grey}  |\n",
      "|Jefferson |{eye -> , hair -> brown}     |\n",
      "+----------+-----------------------------+\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- hair: string (nullable = true)\n",
      " |-- eye: string (nullable = true)\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType, MapType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('properties', MapType(StringType(),StringType()),True)\n",
    "])\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "dataDictionary = [\n",
    "        ('James',{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',{'hair':'brown','eye':None}),\n",
    "        ('Robert',{'hair':'red','eye':'black'}),\n",
    "        ('Washington',{'hair':'grey','eye':'grey'}),\n",
    "        ('Jefferson',{'hair':'brown','eye':''})\n",
    "        ]\n",
    "df = spark.createDataFrame(data=dataDictionary, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "df3=df.rdd.map(lambda x: \\\n",
    "    (x.name,x.properties[\"hair\"],x.properties[\"eye\"])) \\\n",
    "    .toDF([\"name\",\"hair\",\"eye\"])\n",
    "df3.printSchema()\n",
    "df3.show()\n",
    "\n",
    "df.withColumn(\"hair\",df.properties.getItem(\"hair\")) \\\n",
    "  .withColumn(\"eye\",df.properties.getItem(\"eye\")) \\\n",
    "  .drop(\"properties\") \\\n",
    "  .show()\n",
    "\n",
    "df.withColumn(\"hair\",df.properties[\"hair\"]) \\\n",
    "  .withColumn(\"eye\",df.properties[\"eye\"]) \\\n",
    "  .drop(\"properties\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb653a5-0d2d-4c71-b0db-685dc58bddd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|      name| key|value|\n",
      "+----------+----+-----+\n",
      "|     James| eye|brown|\n",
      "|     James|hair|black|\n",
      "|   Michael| eye| null|\n",
      "|   Michael|hair|brown|\n",
      "|    Robert| eye|black|\n",
      "|    Robert|hair|  red|\n",
      "|Washington| eye| grey|\n",
      "|Washington|hair| grey|\n",
      "| Jefferson| eye|     |\n",
      "| Jefferson|hair|brown|\n",
      "+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "df.select(df.name,explode(df.properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f77bcc1-110e-4132-b5bf-132f1329256c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|map_keys(properties)|\n",
      "+----------+--------------------+\n",
      "|     James|         [eye, hair]|\n",
      "|   Michael|         [eye, hair]|\n",
      "|    Robert|         [eye, hair]|\n",
      "|Washington|         [eye, hair]|\n",
      "| Jefferson|         [eye, hair]|\n",
      "+----------+--------------------+\n",
      "\n",
      "+----------+----------------------+\n",
      "|      name|map_values(properties)|\n",
      "+----------+----------------------+\n",
      "|     James|        [brown, black]|\n",
      "|   Michael|         [null, brown]|\n",
      "|    Robert|          [black, red]|\n",
      "|Washington|          [grey, grey]|\n",
      "| Jefferson|             [, brown]|\n",
      "+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import map_keys\n",
    "df.select(df.name,map_keys(df.properties)).show()\n",
    "\n",
    "from pyspark.sql.functions import map_values\n",
    "df.select(df.name,map_values(df.properties)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863cab3-aaf8-4f30-883c-1689851e972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MapType is a map data structure that is used to store key key-value pairs similar to Python Dictionary (Dic), keys and values type of map should be of a type that extends DataType. Key wonâ€™t accept null/None values whereas map of the key can have None/Null value.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
