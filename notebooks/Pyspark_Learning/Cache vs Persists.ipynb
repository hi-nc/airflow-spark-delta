{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f288e5a-019f-42ba-8f9f-6ef0640c5e7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Cache - programming mechanism which an option to store data in memory across nodes\n",
    "Persists - programming mechanism which an option to store data in memory or in disc across nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD Cache\n",
    "PySpark RDD cache() method by default saves RDD computation to storage level `MEMORY_ONLY` meaning it will store the data in the JVM heap as unserialized objects.\n",
    "\n",
    "PySpark cache() method in RDD class internally calls persist() method which in turn uses sparkSession.sharedState.cacheManager.cacheQuery to cache the result set of RDD. Letâ€™s look at an example.\n",
    "\n",
    "\n",
    "# cache()\n",
    "cachedRdd = rdd.cache()\n",
    "RDD Persist\n",
    "Using persist() method, you can store the RDD in one of the storage levels\n",
    "\n",
    "MEMORY_ONLY, MEMORY_ONLY_SER, MEMORY_AND_DISK, MEMORY_AND_DISK_SER, DISK_ONLY, MEMORY_ONLY_2, MEMORY_AND_DISK_2 and more.\n",
    "\n",
    "\n",
    "# persist()\n",
    "import pyspark\n",
    "dfPersist = rdd.persist(pyspark.StorageLevel.MEMORY_ONLY)\n",
    "dfPersist.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD Unpersist\n",
    "PySpark systematically monitors each invocation of persist() and cache(), scrutinizing usage across every node. It automatically discards persisted data that remains unused or employs the least-recently-used (LRU) algorithm. Additionally, users can manually remove persisted data using the unpersist() method. This action marks the RDD as non-persistent and eradicates all associated blocks from both memory and disk.\n",
    "\n",
    "\n",
    "# unpersist()\n",
    "rddPersist2 = rddPersist.unpersist()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Cache vs Persists",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
