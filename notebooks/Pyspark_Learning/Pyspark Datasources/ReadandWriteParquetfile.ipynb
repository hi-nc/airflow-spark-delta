{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a5bf96-5afc-4a8d-8098-4466d7b84000",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pyspark SQL provides methods to read Parquet file into DataFrame and write DataFrame to Parquet files, parquet() function\n",
    "from DataFrameReader and DataFrameWriter are used to read from and write/create a Parquet file respectively. Parquet files\n",
    "maintain the schema along with the data hence it is used to process a structured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020d950-e204-4d0c-a9a6-7ccc224f4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Apache Parquet file is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the \n",
    "choice of data processing framework, data model, or programming language.\n",
    "While querying columnar storage, it skips the nonrelevant data very quickly, making faster query execution. \n",
    "As a result aggregation queries consume less time compared to row-oriented databases.\n",
    "It is able to support advanced nested data structures.\n",
    "Parquet supports efficient compression options and encoding schemes.\n",
    "It also reduces data storage by 75% on average. Pyspark by default supports Parquet in its library hence we donâ€™t need \n",
    "to add any dependency libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd9f6f7-b7f4-474e-b605-dd610130b0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|dob  |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "| Michael |      Rose|        |40288|     M|  4000|\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "| Michael |      Rose|        |40288|     M|  4000|\n",
      "|   James |          |   Smith|36636|     M|  3000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "\n",
      "+---------+----------+--------+-----+------+\n",
      "|firstname|middlename|lastname|dob  |salary|\n",
      "+---------+----------+--------+-----+------+\n",
      "|Robert   |          |Williams|42114|4000  |\n",
      "|Michael  |Rose      |        |40288|4000  |\n",
      "|James    |          |Smith   |36636|3000  |\n",
      "+---------+----------+--------+-----+------+\n",
      "\n",
      "+---------+----------+--------+-----+------+\n",
      "|firstname|middlename|lastname|  dob|salary|\n",
      "+---------+----------+--------+-----+------+\n",
      "|   Maria |      Anne|   Jones|39192|  4000|\n",
      "|      Jen|      Mary|   Brown|     |    -1|\n",
      "+---------+----------+--------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"parquetFile\").getOrCreate()\n",
    "data =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.printSchema()\n",
    "# Write DataFrame to parquet file using write.parquet()\n",
    "df.write.mode('overwrite').parquet(\"/home/jovyan/work/data/raw/parquetfiles/people.parquet\")\n",
    "\n",
    "# Read parquet file using read.parquet()\n",
    "parDF=spark.read.parquet(\"/home/jovyan/work/data/raw/parquetfiles/people.parquet\")\n",
    "parDF.show(truncate=False)\n",
    "\n",
    "#Using append and overwrite to save parquet file\n",
    "df.write.mode('append').parquet(\"/home/jovyan/work/data/raw/parquetfiles/people.parquet\")\n",
    "df.write.mode('overwrite').parquet(\"/home/jovyan/work/data/raw/parquetfiles/people.parquet\")\n",
    "\n",
    "# Using spark.sql\n",
    "df.createOrReplaceTempView(\"ParquetTable\")\n",
    "parkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000 \")\n",
    "parkSQL.show()\n",
    "\n",
    "# Create temp view on Parquet file\n",
    "# Drop the existing temporary view if it exists\n",
    "spark.sql(\"DROP VIEW IF EXISTS PERSON\")\n",
    "spark.sql(\"CREATE TEMPORARY VIEW PERSON USING parquet OPTIONS (path \\\"/home/jovyan/work/data/raw/parquetfiles/people.parquet\\\")\")\n",
    "spark.sql(\"SELECT * FROM PERSON\").show()\n",
    "\n",
    "#Create Parquet partition file\n",
    "df.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"/home/jovyan/work/data/raw/parquetfiles/people2.parquet\")\n",
    "\n",
    "#Retrieving from a partitioned Parquet file\n",
    "parDF2=spark.read.parquet(\"/home/jovyan/work/data/raw/parquetfiles/people2.parquet/gender=M\")\n",
    "parDF2.show(truncate=False)\n",
    "\n",
    "# Create a temporary view on partitioned Parquet file\n",
    "spark.sql(\"DROP VIEW IF EXISTS PERSON2\")\n",
    "spark.sql(\"CREATE TEMPORARY VIEW PERSON2 USING parquet OPTIONS (path \\\"/home/jovyan/work/data/raw/parquetfiles/people2.parquet/gender=F\\\")\")\n",
    "spark.sql(\"SELECT * FROM PERSON2\" ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
