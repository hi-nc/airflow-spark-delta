{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98738ff9-3a7d-4a41-a4e6-6a1e056156ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use PySpark withColumnRenamed() to rename a DataFrame column, we often need to rename one column or multiple (or all) columns on PySpark DataFrame, you can do this in several ways. When columns are nested it becomes complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21250956-7047-47bf-91c7-b7acc642cf8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- newCol1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- newCol2: string (nullable = true)\n",
      " |-- newCol3: string (nullable = true)\n",
      " |-- newCol4: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n",
    "\n",
    "# PySpark withColumnRenamed – To rename DataFrame column name\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()\n",
    "\n",
    "# PySpark withColumnRenamed – To rename multiple columns  \n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()\n",
    "\n",
    "# Using PySpark StructType – To rename a nested column in Dataframe\n",
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "    \n",
    "df.select(col(\"name\").cast(schema2),\n",
    "  col(\"dob\"),\n",
    "  col(\"gender\"),\n",
    "  col(\"salary\")) \\\n",
    "    .printSchema()    \n",
    "\n",
    "# Using Select – To rename nested elements. \n",
    "df.select(col(\"name.firstname\").alias(\"fname\"),\n",
    "  col(\"name.middlename\").alias(\"mname\"),\n",
    "  col(\"name.lastname\").alias(\"lname\"),\n",
    "  col(\"dob\"),col(\"gender\"),col(\"salary\")) \\\n",
    "  .printSchema()\n",
    "  \n",
    "#Using PySpark DataFrame withColumn – To rename nested columns\n",
    "df4 = df.withColumn(\"fname\",col(\"name.firstname\")) \\\n",
    "      .withColumn(\"mname\",col(\"name.middlename\")) \\\n",
    "      .withColumn(\"lname\",col(\"name.lastname\")) \\\n",
    "      .drop(\"name\")\n",
    "df4.printSchema()\n",
    "\n",
    "#Using toDF() – To change all columns in a PySpark DataFrame\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a27381-7668-44b4-a7a8-cae7c8b50f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
