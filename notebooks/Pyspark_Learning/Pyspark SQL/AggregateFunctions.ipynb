{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b6b7a-5d94-49c8-b95a-e2da64cc02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aggregate functions in PySpark are essential for summarizing data across distributed datasets. They allow computations like \n",
    "sum, average, count, maximum, and minimum to be performed efficiently in parallel across multiple nodes in a cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdac052-a62e-4aa9-ad8e-c93e82b5c62c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n",
      "approx_count_distinct: 6\n",
      "avg: 3400.0\n",
      "+------------------------------------------------------------+\n",
      "|collect_list(salary)                                        |\n",
      "+------------------------------------------------------------+\n",
      "|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n",
      "+------------------------------------------------------------+\n",
      "\n",
      "+------------------------------------+\n",
      "|collect_set(salary)                 |\n",
      "+------------------------------------+\n",
      "|[4600, 3000, 3900, 4100, 3300, 2000]|\n",
      "+------------------------------------+\n",
      "\n",
      "+----------------------------------+\n",
      "|count(DISTINCT department, salary)|\n",
      "+----------------------------------+\n",
      "|8                                 |\n",
      "+----------------------------------+\n",
      "\n",
      "Distinct Count of Department &amp; Salary: 8\n",
      "count: Row(count(salary)=10)\n",
      "+-------------+\n",
      "|first(salary)|\n",
      "+-------------+\n",
      "|3000         |\n",
      "+-------------+\n",
      "\n",
      "+------------+\n",
      "|last(salary)|\n",
      "+------------+\n",
      "|4100        |\n",
      "+------------+\n",
      "\n",
      "+-------------------+\n",
      "|kurtosis(salary)   |\n",
      "+-------------------+\n",
      "|-0.6467803030303032|\n",
      "+-------------------+\n",
      "\n",
      "+-----------+\n",
      "|max(salary)|\n",
      "+-----------+\n",
      "|4600       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|min(salary)|\n",
      "+-----------+\n",
      "|2000       |\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|avg(salary)|\n",
      "+-----------+\n",
      "|3400.0     |\n",
      "+-----------+\n",
      "\n",
      "+--------------------+\n",
      "|skewness(salary)    |\n",
      "+--------------------+\n",
      "|-0.12041791181069571|\n",
      "+--------------------+\n",
      "\n",
      "+-------------------+-------------------+------------------+\n",
      "|stddev_samp(salary)|stddev_samp(salary)|stddev_pop(salary)|\n",
      "+-------------------+-------------------+------------------+\n",
      "|765.9416862050705  |765.9416862050705  |726.636084983398  |\n",
      "+-------------------+-------------------+------------------+\n",
      "\n",
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|34000      |\n",
      "+-----------+\n",
      "\n",
      "+--------------------+\n",
      "|sum(DISTINCT salary)|\n",
      "+--------------------+\n",
      "|20900               |\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/functions.py:316: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n",
      "  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+---------------+\n",
      "|var_samp(salary) |var_samp(salary) |var_pop(salary)|\n",
      "+-----------------+-----------------+---------------+\n",
      "|586666.6666666666|586666.6666666666|528000.0       |\n",
      "+-----------------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import approx_count_distinct,collect_list\n",
    "from pyspark.sql.functions import collect_set,sum,avg,max,countDistinct,count\n",
    "from pyspark.sql.functions import first, last, kurtosis, min, mean, skewness \n",
    "from pyspark.sql.functions import stddev, stddev_samp, stddev_pop, sumDistinct\n",
    "from pyspark.sql.functions import variance,var_samp,  var_pop\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[1]\").appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "  ]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "  \n",
    "  \n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "#In PySpark approx_count_distinct() function returns the count of distinct items in a group.\n",
    "print(\"approx_count_distinct: \" + str(df.select(approx_count_distinct(\"salary\")).collect()[0][0]))\n",
    "\n",
    "#avg() function returns the average of values in the input column.\n",
    "print(\"avg: \" + str(df.select(avg(\"salary\")).collect()[0][0]))\n",
    "\n",
    "#collect_list() function returns all values from an input column with duplicates.\n",
    "df.select(collect_list(\"salary\")).show(truncate=False)\n",
    "\n",
    "#collect_set() function returns all values from an input column with duplicate values eliminated.\n",
    "df.select(collect_set(\"salary\")).show(truncate=False)\n",
    "\n",
    "#countDistinct() function returns the number of distinct elements in a columns\n",
    "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
    "df2.show(truncate=False)\n",
    "print(\"Distinct Count of Department &amp; Salary: \"+str(df2.collect()[0][0]))\n",
    "\n",
    "#count() function returns number of elements in a column.\n",
    "print(\"count: \"+str(df.select(count(\"salary\")).collect()[0]))\n",
    "\n",
    "#first() function returns the first element in a column when ignoreNulls is set to true, it returns the first non-null element.\n",
    "df.select(first(\"salary\")).show(truncate=False)\n",
    "\n",
    "#last() function returns the last element in a column. when ignoreNulls is set to true, it returns the last non-null element.\n",
    "df.select(last(\"salary\")).show(truncate=False)\n",
    "\n",
    "#kurtosis() function returns the kurtosis of the values in a group.\n",
    "#\"skewness\" measures the asymmetry of a data distribution, indicating whether the data is leaning more towards one side than \n",
    "#the other, while \"kurtosis\" measures the \"tailedness\" of a distribution, showing how concentrated the data is around the mean\n",
    "#and how heavy the tails are compared to a normal distribution; essentially, skewness looks at the symmetry,and kurtosis examines the peakiness of a distribution\n",
    "df.select(kurtosis(\"salary\")).show(truncate=False)\n",
    "\n",
    "\n",
    "df.select(max(\"salary\")).show(truncate=False)\n",
    "df.select(min(\"salary\")).show(truncate=False)\n",
    "\n",
    "#mean() function returns the average of the values in a column. Alias for Avg\n",
    "df.select(mean(\"salary\")).show(truncate=False)\n",
    "\n",
    "#skewness() function returns the skewness of the values in a group.\n",
    "df.select(skewness(\"salary\")).show(truncate=False)\n",
    "\n",
    "#stddev() alias for stddev_samp.\n",
    "#stddev_samp() function returns the sample standard deviation of values in a column.\n",
    "#stddev_pop() function returns the population standard deviation of the values in a column.\n",
    "df.select(stddev(\"salary\"), stddev_samp(\"salary\"), stddev_pop(\"salary\")).show(truncate=False)\n",
    "\n",
    "df.select(sum(\"salary\")).show(truncate=False)\n",
    "\n",
    "#sumDistinct() function returns the sum of all distinct values in a column.\n",
    "df.select(sumDistinct(\"salary\")).show(truncate=False)\n",
    "\n",
    "#variance() alias for var_samp\n",
    "#var_samp() function returns the unbiased variance of the values in a column.\n",
    "#var_pop() function returns the population variance of the values in a column.\n",
    "df.select(variance(\"salary\"),var_samp(\"salary\"),var_pop(\"salary\")).show(truncate=False)\n",
    "\n",
    "#\"variance\" is a measure of how spread out a set of data is from its mean, calculated by finding the average of the squared \n",
    "#differences from the mean, while \"standard deviation\" is the square root of the variance, which means it represents the \n",
    "#average deviation of data points from the mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
