{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd711e-c9d8-4bc2-9e2b-daac2cc016bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PySpark provides two transform() functions one with DataFrame and another in pyspark.sql.functions.\n",
    "\n",
    "pyspark.sql.DataFrame.transform() â€“ Available since Spark 3.0.Used to chain the custom transformations and this function returns the new DataFrame after applying the specified transformations.\n",
    "This function always returns the same number of rows that exists on the input PySpark DataFrame.\n",
    "pyspark.sql.functions.transform() - The PySpark sql.functions.transform() is used to apply the transformation on a column of type Array. This function applies the specified transformation \n",
    "on every element of the array and returns an object of ArrayType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c55555c-f1f3-4b97-be58-3404bec7215d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CourseName: string (nullable = true)\n",
      " |-- fee: long (nullable = true)\n",
      " |-- discount: long (nullable = true)\n",
      "\n",
      "+----------+----+--------+\n",
      "|CourseName|fee |discount|\n",
      "+----------+----+--------+\n",
      "|Java      |4000|5       |\n",
      "|Python    |4600|10      |\n",
      "|Scala     |4100|15      |\n",
      "|Scala     |4500|15      |\n",
      "|PHP       |3000|20      |\n",
      "+----------+----+--------+\n",
      "\n",
      "+----------+----+--------+-------+--------------+\n",
      "|CourseName| fee|discount|new_fee|discounted_fee|\n",
      "+----------+----+--------+-------+--------------+\n",
      "|      JAVA|4000|       5|   3000|        2850.0|\n",
      "|    PYTHON|4600|      10|   3600|        3240.0|\n",
      "|     SCALA|4100|      15|   3100|        2635.0|\n",
      "|     SCALA|4500|      15|   3500|        2975.0|\n",
      "|       PHP|3000|      20|   2000|        1600.0|\n",
      "+----------+----+--------+-------+--------------+\n",
      "\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Languages1: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Languages2: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+----------------+------------------+---------------+\n",
      "|            Name|        Languages1|     Languages2|\n",
      "+----------------+------------------+---------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|\n",
      "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|\n",
      "+----------------+------------------+---------------+\n",
      "\n",
      "+------------------+\n",
      "|        languages1|\n",
      "+------------------+\n",
      "|[JAVA, SCALA, C++]|\n",
      "|[SPARK, JAVA, C++]|\n",
      "|      [CSHARP, VB]|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "            .appName('SparkByExamples.com') \\\n",
    "            .getOrCreate()\n",
    "\n",
    "# Prepare Data\n",
    "simpleData = ((\"Java\",4000,5), \\\n",
    "    (\"Python\", 4600,10),  \\\n",
    "    (\"Scala\", 4100,15),   \\\n",
    "    (\"Scala\", 4500,15),   \\\n",
    "    (\"PHP\", 3000,20),  \\\n",
    "  )\n",
    "columns= [\"CourseName\", \"fee\", \"discount\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Custom transformation 1\n",
    "from pyspark.sql.functions import upper\n",
    "def to_upper_str_columns(df):\n",
    "    return df.withColumn(\"CourseName\",upper(df.CourseName))\n",
    "\n",
    "# Custom transformation 2\n",
    "def reduce_price(df,reduceBy):\n",
    "    return df.withColumn(\"new_fee\",df.fee - reduceBy)\n",
    "\n",
    "# Custom transformation 3\n",
    "def apply_discount(df):\n",
    "    return df.withColumn(\"discounted_fee\",  \\\n",
    "             df.new_fee - (df.new_fee * df.discount) / 100)\n",
    "\n",
    "# transform() usage\n",
    "df2 = df.transform(to_upper_str_columns) \\\n",
    "        .transform(reduce_price,1000) \\\n",
    "        .transform(apply_discount) \n",
    "                \n",
    "df2.show()\n",
    "\n",
    "# Create DataFrame with Array\n",
    "data = [\n",
    " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]),\n",
    " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]),\n",
    " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"])\n",
    "]\n",
    "df = spark.createDataFrame(data=data,schema=[\"Name\",\"Languages1\",\"Languages2\"])\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "# using transform() SQL function\n",
    "from pyspark.sql.functions import upper\n",
    "from pyspark.sql.functions import transform\n",
    "df.select(transform(\"Languages1\", lambda x: upper(x)).alias(\"languages1\")) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fdd7b-19a0-4d24-8460-6a00de3616e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
